"use strict";(globalThis.webpackChunkblog2=globalThis.webpackChunkblog2||[]).push([[8365],{49465(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});var s=t(85181),r=t(62615),i=t(10253);const o={title:"Understanding How LLMs Work with a Doctor's Clinic Analogy",description:"Break down the inner workings of Large Language Models (LLMs) using an easy-to-follow analogy of a doctor's clinic. Learn about tokenization, embeddings, transformer architecture, and more.",tags:["AI-for-frontends"],date:new Date("2025-05-01T15:30:22.000Z"),authors:["dhbalaji"],image:"/img/2025/doctor-patient-ai-illustration.png",keywords:["ai","frontends","explaination"]},a="\ud83c\udfe5 How a Doctor\u2019s Clinic Explains the Inner Workings of LLMs",l={authorsImageUrls:[void 0]},c=[{value:"Characters in the Community Clinic Example",id:"characters-in-the-community-clinic-example",level:2},{value:"Step 1: Patient Describes the Issue to Doctor",id:"step-1-patient-describes-the-issue-to-doctor",level:2},{value:"Step 2: Doctor Comprehends the Patient Problem",id:"step-2-doctor-comprehends-the-patient-problem",level:2},{value:"Step 3: Doctor Runs Diagnosis Internally",id:"step-3-doctor-runs-diagnosis-internally",level:2},{value:"Step 4: Doctor Considers Constraints (like budget)",id:"step-4-doctor-considers-constraints-like-budget",level:2},{value:"Step 5: Doctor Writes a Prescription",id:"step-5-doctor-writes-a-prescription",level:2},{value:"Step 6: Doctor Shares the Prescription with the Patient",id:"step-6-doctor-shares-the-prescription-with-the-patient",level:2},{value:"Bonus Step: The Doctor Remembers Your Previous Visit",id:"bonus-step-the-doctor-remembers-your-previous-visit",level:2},{value:"Summary",id:"summary",level:2},{value:"\u2728 Takeaways for Developers",id:"-takeaways-for-developers",level:2}];function d(e){const n={blockquote:"blockquote",br:"br",em:"em",h2:"h2",hr:"hr",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:t(35509).A+"",width:"1000",height:"666"})}),"\n",(0,r.jsxs)(n.p,{children:["Large Language Models (LLMs) are revolutionizing the way we build intelligent applications\u2014especially in frontend development. From ChatGPT to custom AI copilots, LLMs are everywhere. But have you ever wondered ",(0,r.jsx)(n.strong,{children:"how LLMs actually work"})," under the hood?"]}),"\n",(0,r.jsxs)(n.p,{children:["The theory behind LLMs can be complex\u2014terms like ",(0,r.jsx)(n.em,{children:"embeddings"}),", ",(0,r.jsx)(n.em,{children:"transformers"}),", ",(0,r.jsx)(n.em,{children:"tokenization"}),", and ",(0,r.jsx)(n.em,{children:"vector space"})," often feel overwhelming. That\u2019s why I\u2019m using a familiar analogy: a visit to a ",(0,r.jsx)(n.strong,{children:"local doctor\u2019s clinic"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["This blog post breaks down ",(0,r.jsx)(n.strong,{children:"the internal architecture of LLMs"})," using a real-world story that\u2019s easy to visualize and remember. Whether you're a developer exploring AI integration, an engineer curious about embeddings, or someone building chat interfaces, this analogy-driven explanation will help you understand:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"What tokenization really means"}),"\n",(0,r.jsx)(n.li,{children:"Why vectors and embeddings are essential"}),"\n",(0,r.jsx)(n.li,{children:'How transformers "think" using attention'}),"\n",(0,r.jsx)(n.li,{children:"Why temperature affects LLM creativity"}),"\n",(0,r.jsx)(n.li,{children:"How memory and context shape outputs"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Let\u2019s walk into the clinic. \ud83d\udeb6\u200d\u2642\ufe0f\ud83d\udc8a"}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"characters-in-the-community-clinic-example",children:"Characters in the Community Clinic Example"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"User"})," \u2013 A person interacting with the LLM (the patient)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"LLM"})," \u2013 The large language model (the doctor)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Internals"})," \u2013 Sequence of steps the model uses to generate a response (diagnostic workflow)"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"step-1-patient-describes-the-issue-to-doctor",children:"Step 1: Patient Describes the Issue to Doctor"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Scene:"}),(0,r.jsx)(n.br,{}),"\n","The patient walks into the clinic."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Conversation:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Doctor: Hi, please sit down."}),"\n",(0,r.jsx)(n.li,{children:"Patient: Thank you."}),"\n",(0,r.jsx)(n.li,{children:"Doctor: Tell me."}),"\n",(0,r.jsx)(n.li,{children:"Patient: I got back from my friend\u2019s wedding 2 days back. Since yesterday, I feel cold and have body pains."}),"\n",(0,r.jsx)(n.li,{children:"Doctor: (listening) hmm."}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"LLM Analogy:"}),(0,r.jsx)(n.br,{}),"\n","This step is like ",(0,r.jsx)(n.strong,{children:"tokenization"})," \u2014 breaking the input sentence into smaller units (tokens) that the machine can understand."]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Step 1 - Tokenizer:"}),(0,r.jsx)(n.br,{}),"\n","Converts input from human language to machine-readable tokens."]}),"\n"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Input:"})," Plain text / story"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Output:"}),' Word tokens (e.g., "wedding", "cold", "pains")']}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"step-2-doctor-comprehends-the-patient-problem",children:"Step 2: Doctor Comprehends the Patient Problem"}),"\n",(0,r.jsx)(n.p,{children:"The doctor interprets the patient\u2019s words and thinks in terms of temperature, symptoms, etc. They may even order diagnostic tests for more data."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"LLM Analogy:"}),(0,r.jsx)(n.br,{}),"\n","This is like the ",(0,r.jsx)(n.strong,{children:"embedding layer"}),", where word tokens are turned into number arrays (vectors) that hold semantic meaning."]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Step 2 - Embedding Layer:"}),(0,r.jsx)(n.br,{}),"\n","Converts tokens into vector form for semantic understanding."]}),"\n"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Input:"})," Word tokens"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Output:"})," Vectors that represent meaning (like symptoms turned into medical data)"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"step-3-doctor-runs-diagnosis-internally",children:"Step 3: Doctor Runs Diagnosis Internally"}),"\n",(0,r.jsx)(n.p,{children:"The doctor thinks through the problem using experience and logic\u2014checking symptoms against patterns they\u2019ve seen before."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"LLM Analogy:"}),(0,r.jsx)(n.br,{}),"\n","This is the ",(0,r.jsx)(n.strong,{children:"transformer architecture"}),"\u2014especially self-attention layers, which compare words across the sentence to extract meaning and decide what matters most."]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Step 3 - Transformer Layers:"}),(0,r.jsx)(n.br,{}),"\n","Deep learning steps like self-attention and feedforward networks."]}),"\n"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Input:"})," Vectors"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Output:"})," Context-aware vectors based on internal learned patterns"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"step-4-doctor-considers-constraints-like-budget",children:"Step 4: Doctor Considers Constraints (like budget)"}),"\n",(0,r.jsx)(n.p,{children:"Doctors don\u2019t always prescribe expensive tests\u2014patient affordability, practicality, and history all affect decisions."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"LLM Analogy:"}),(0,r.jsx)(n.br,{}),"\n","This step is like ",(0,r.jsx)(n.strong,{children:"positional encoding"}),"\u2014ensuring the model understands the order and structure of the sentence."]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Step 4 - Positional Encoding:"}),(0,r.jsx)(n.br,{}),"\n","Adds position-related meaning to vectors."]}),"\n"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Input:"})," Related vector tokens"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Output:"})," Ordered vector tokens based on sentence position"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"step-5-doctor-writes-a-prescription",children:"Step 5: Doctor Writes a Prescription"}),"\n",(0,r.jsx)(n.p,{children:"The doctor now documents the diagnosis and treatment. It\u2019s a direct result of structured thinking and patient input."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"LLM Analogy:"}),(0,r.jsx)(n.br,{}),"\n","This is where the model ",(0,r.jsx)(n.strong,{children:"decodes"})," the internal vector into a predicted sequence of tokens."]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Step 5 - Decoder:"}),(0,r.jsx)(n.br,{}),"\n","Generates output tokens based on model\u2019s confidence and logic."]}),"\n"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Input:"})," Positional vectors"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Output:"})," Probable tokens in correct context"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"step-6-doctor-shares-the-prescription-with-the-patient",children:"Step 6: Doctor Shares the Prescription with the Patient"}),"\n",(0,r.jsx)(n.p,{children:"The final interaction. If the patient is nervous, doctor might tweak the recommendation. This is where human nuance enters."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"LLM Analogy:"}),(0,r.jsx)(n.br,{}),"\n","The LLM now converts tokens back into human-readable words. Here, ",(0,r.jsx)(n.strong,{children:"temperature"})," plays a role in how creative or safe the response is."]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Step 6 - Output Layer:"}),(0,r.jsx)(n.br,{}),"\n","Converts final vector into output text based on temperature setting."]}),"\n"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Input:"})," Final vector"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Output:"})," Natural language sentence"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"bonus-step-the-doctor-remembers-your-previous-visit",children:"Bonus Step: The Doctor Remembers Your Previous Visit"}),"\n",(0,r.jsxs)(n.p,{children:["LLMs with ",(0,r.jsx)(n.strong,{children:"memory or context windows"})," can remember prior conversations, like a doctor recognizing returning patients. This helps give better, contextual responses in multi-turn dialogues."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,r.jsx)(n.p,{children:'Just like a good doctor doesn\u2019t Google your symptoms in front of you, a well-trained LLM doesn\u2019t "think" in real-time. It applies complex math on pre-learned data to predict and autocomplete responses.'}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:"Words \u2192 Tokens \u2192 Vectors \u2192 Patterns \u2192 Tokens \u2192 Words"})}),"\n",(0,r.jsxs)(n.li,{children:["Everything happens in ",(0,r.jsx)(n.strong,{children:"vector space"}),', not in "language" as humans know it.']}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["If you\u2019re building with tools like ",(0,r.jsx)(n.strong,{children:"LangChain"}),", ",(0,r.jsx)(n.strong,{children:"OpenAI"}),", or ",(0,r.jsx)(n.strong,{children:"embedding-powered RAG applications"}),", understanding these LLM fundamentals gives you a huge advantage."]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsx)(n.p,{children:'\ud83e\udde0 "A well-trained LLM is just a super-fast autocomplete that has read the entire internet."'}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-takeaways-for-developers",children:"\u2728 Takeaways for Developers"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Tokenization = Parsing human input"}),"\n",(0,r.jsx)(n.li,{children:"Embedding = Understanding meaning"}),"\n",(0,r.jsx)(n.li,{children:"Transformer = Core logic engine / Deep learning"}),"\n",(0,r.jsx)(n.li,{children:"Positional Encoding = Sentence structure"}),"\n",(0,r.jsx)(n.li,{children:"Decoding = Constructing a response"}),"\n",(0,r.jsx)(n.li,{children:"Temperature = Tuning creativity"}),"\n",(0,r.jsx)(n.li,{children:"Context = Remembering past interactions"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"LLMs don\u2019t reason like humans\u2014but they recognize patterns with superhuman speed. Now you can too. If you like this story, share it on social media."})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},35509(e,n,t){t.d(n,{A:()=>s});const s=t.p+"assets/images/doctor-patient-ai-illustration-01ba81e9b1cfc24251a3212175a35e3d.webp"},10253(e,n,t){t.d(n,{R:()=>o,x:()=>a});var s=t(59471);const r={},i=s.createContext(r);function o(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),s.createElement(i.Provider,{value:n},e.children)}},85181(e){e.exports=JSON.parse('{"permalink":"/blog/2025/understanding-llm-with-hospital-example","source":"@site/blog/2025/understanding-llm-with-hospital-example.md","title":"Understanding How LLMs Work with a Doctor\'s Clinic Analogy","description":"Break down the inner workings of Large Language Models (LLMs) using an easy-to-follow analogy of a doctor\'s clinic. Learn about tokenization, embeddings, transformer architecture, and more.","date":"2025-05-01T15:30:22.000Z","tags":[{"inline":true,"label":"AI-for-frontends","permalink":"/blog/tags/ai-for-frontends"}],"readingTime":4.05,"hasTruncateMarker":false,"authors":[{"name":"D Balaji","title":"Lead Design Technologist","url":"https://github.com/dhbalaji","imageURL":"https://avatars.githubusercontent.com/u/3672491?v=4","key":"dhbalaji","page":null}],"frontMatter":{"title":"Understanding How LLMs Work with a Doctor\'s Clinic Analogy","description":"Break down the inner workings of Large Language Models (LLMs) using an easy-to-follow analogy of a doctor\'s clinic. Learn about tokenization, embeddings, transformer architecture, and more.","tags":["AI-for-frontends"],"date":"2025-05-01T15:30:22.000Z","authors":["dhbalaji"],"image":"/img/2025/doctor-patient-ai-illustration.png","keywords":["ai","frontends","explaination"]},"unlisted":false,"prevItem":{"title":"Back to stage, My Comeback to Toastmasters and First Visit to Hosur Toastmasters Club","permalink":"/blog/2025/hosur-toastmasters-journey-to-confidence-starts-here"},"nextItem":{"title":"5 Things I am Letting Go of in 2025 - Building a Not-To-Do List","permalink":"/blog/2024/5-things-not-to-do-in-2025"}}')}}]);